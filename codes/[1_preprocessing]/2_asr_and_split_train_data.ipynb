{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fc1dec",
   "metadata": {},
   "source": [
    "# 一、批量 ASR 转写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1749cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, whisper, tqdm, os\n",
    "from opencc import OpenCC\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c927aa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:37<00:00, 3.86MiB/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data_map.csv\")\n",
    "model = whisper.load_model(\"base\")  \n",
    "cc = OpenCC('t2s')  # 繁转简"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c5e5577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取json_path中的json文件，获取title放入real_text列\n",
    "# 这里json_path列存的路径是相对于当前notebook的路径\n",
    "# 若文件缺失/字段缺失，可按需补充异常处理\n",
    "def load_title(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data.get(\"title\", \"null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6cc6807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_to_simplified(path):\n",
    "    r = model.transcribe(path, language=\"zh\", task=\"transcribe\")\n",
    "    text = r[\"text\"].strip()\n",
    "    text_simplified = cc.convert(text)  # 转成简体\n",
    "    return text_simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5608f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:19<00:00,  7.16it/s]\n"
     ]
    }
   ],
   "source": [
    "asr_results = []\n",
    "for p in tqdm.tqdm(df[\"audio_path\"]):\n",
    "    r = transcribe_to_simplified(p)\n",
    "    asr_results.append(r.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "471e6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"asr_text\"] = asr_results\n",
    "df[\"real_text\"] = df[\"json_path\"].apply(load_title)\n",
    "df.to_csv(\"../../map_with_asr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72891b",
   "metadata": {},
   "source": [
    "# 二、划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04e70e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f998148",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV  = \"../../map_with_asr.csv\" \n",
    "OUTPUT_CSV =  \"../../map_with_asr_split.csv\"\n",
    "TRAIN_CSV  = \"../../train.csv\"\n",
    "VAL_CSV    = \"../../val.csv\"\n",
    "TEST_CSV   = \"../../test.csv\"\n",
    "\n",
    "RATIOS = (0.7, 0.15, 0.15)  # 训练/验证/测试占比\n",
    "SEED = 4022510316           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c1614ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../../map_with_asr_split.csv (train=700, val=150, test=150)\n",
      "Saved: ../../train.csv, ../../val.csv, ../../test.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(INPUT_CSV)\n",
    "assert abs(sum(RATIOS) - 1.0) < 1e-6, \"RATIOS 之和必须为 1\"\n",
    "\n",
    "n = len(df)\n",
    "rng = np.random.default_rng(SEED)\n",
    "perm = rng.permutation(n)\n",
    "\n",
    "train_end = int(RATIOS[0] * n) # 训练集结束索引\n",
    "val_end   = train_end + int(RATIOS[1] * n) # 验证集结束索引\n",
    "\n",
    "# 划分数据集\n",
    "split = np.array([\"train\"] * n)\n",
    "split[perm[train_end:val_end]] = \"val\"\n",
    "split[perm[val_end:]] = \"test\"\n",
    "\n",
    "df[\"split\"] = split\n",
    "df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8-sig\") # 输出总表\n",
    "print(f\"Saved: {OUTPUT_CSV} (train={np.sum(split=='train')}, val={np.sum(split=='val')}, test={np.sum(split=='test')})\")\n",
    "\n",
    "# 另外输出按 split 划分的三个文件\n",
    "df[df[\"split\"] == \"train\"].to_csv(TRAIN_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "df[df[\"split\"] == \"val\"].to_csv(VAL_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "df[df[\"split\"] == \"test\"].to_csv(TEST_CSV, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"Saved: {TRAIN_CSV}, {VAL_CSV}, {TEST_CSV}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
